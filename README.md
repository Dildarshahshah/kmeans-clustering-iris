# K-Means Clustering on the Iris Dataset 

This notebook demonstrates how to apply **K-Means clustering** to the classic **Iris dataset**, visualize the clusters using **t-SNE**, and use the **Elbow Method** to find the optimal number of clusters.

---

## Key Concepts Covered

- K-Means clustering (unsupervised learning)
- Feature scaling
- Elbow Method for optimal `k`
- Dimensionality reduction using **t-SNE**
- Cluster centroids visualization
- Confusion matrix & silhouette score for evaluation

---

## ğŸ“Š Visualizations Included

- t-SNE 2D plot of clusters
- Cluster centroids (approximate)
- Elbow Method plot
- Confusion matrix comparing clusters to real labels

---

## ğŸ› ï¸ Tools & Libraries

- Python
- scikit-learn
- matplotlib & seaborn
- t-SNE from sklearn

---

## ğŸ“ Try it in Colab

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/kmeans-clustering-iris/blob/main/kmeans_iris_clustering.ipynb)

---

## ğŸ¤“ Dataset

This project uses the **Iris dataset**, available in `sklearn.datasets`.

---

## ğŸ” Next Steps (Ideas)

- Use **UMAP** instead of t-SNE for comparison
- Try clustering on a larger dataset (e.g., digits or MNIST)
- Explore **animation of K-Means** iterations

---

## ğŸ“¬ Connect

If you like this, feel free to â­ï¸ the repo or connect with me on [LinkedIn](https://linkedin.com).

